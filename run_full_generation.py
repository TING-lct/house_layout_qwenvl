"""
æˆ·å‹å¸ƒå±€å®Œæ•´ç”Ÿæˆè„šæœ¬ â€”â€” ç›´æ¥è¿è¡Œå³å¯

è¿è¡Œæ–¹å¼ï¼š
    python run_full_generation.py

éœ€è¦ç¯å¢ƒï¼š
    - GPU (è‡³å°‘16GBæ˜¾å­˜ï¼Œæ¨è24GB)
    - å·²å®‰è£…: transformers, peft, torch, qwen_vl_utils
    - åŸºåº§æ¨¡å‹: Qwen2.5-VL-7B-Instructï¼ˆé¦–æ¬¡è¿è¡Œè‡ªåŠ¨ä¸‹è½½æˆ–æ‰‹åŠ¨æ”¾åˆ° models/ ä¸‹ï¼‰
    - LoRAé€‚é…å™¨: lora_model/ï¼ˆå·²åŒ…å«åœ¨é¡¹ç›®ä¸­ï¼‰

å®Œæ•´ä¼˜åŒ–æµç¨‹ï¼š
    è¾“å…¥å›¾ç‰‡ + å·²æœ‰å‚æ•°
      â†’ æç¤ºè¯å¢å¼ºï¼ˆæ³¨å…¥è®¾è®¡çº¦æŸï¼‰
      â†’ å¤šå€™é€‰ç”Ÿæˆï¼ˆ5ä¸ªä¸åŒæ¸©åº¦é‡‡æ ·ï¼‰
      â†’ äº”ç»´åº¦è¯„ä¼°æ‰“åˆ†
      â†’ é€‰æ‹©æœ€ä¼˜ + è§„åˆ™ä¿®å¤
      â†’ å¦‚æœä¸è¾¾æ ‡: é—®é¢˜æ³¨å…¥Prompt â†’ é‡æ–°ç”Ÿæˆ
      â†’ å¾ªç¯ç›´åˆ°æ»¡æ„ï¼ˆæˆ–è¾¾åˆ°æœ€å¤§è½®æ¬¡ï¼‰
      â†’ è¾“å‡ºæœ€ç»ˆç»“æœ + å¯è§†åŒ–
"""

import json
import sys
import logging
import argparse
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent))

from layout_predictor import LayoutPredictor, build_query

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s [%(name)s] %(message)s',
    datefmt='%H:%M:%S'
)
logger = logging.getLogger("main")


# ==================== æµ‹è¯•ç”¨ä¾‹ ====================
# æ¥è‡ªè®­ç»ƒæ•°æ®é›† dataset_house_floor_test.json ç¬¬ä¸€æ¡æ•°æ®

TEST_CASES = {
    "åŸå¸‚ä¸€å±‚_A0": {
        "image": "LLaMA-Factory/data/input_image/city_l_A0_mix.jpeg",
        "house_type": "åŸå¸‚",
        "floor_type": "ä¸€å±‚",
        "existing_params": {
            "è¾¹ç•Œ": [0, 0, 9300, 11100],
            "ä¸»å…¥å£": [300, 9900, 1200, 1200],
            "å—é‡‡å…‰": [0, -1200, 9300, 1200],
            "åŒ—é‡‡å…‰": [0, 11100, 9300, 1200],
            "ä¸œé‡‡å…‰": [9300, 0, 1200, 11100],
            "é»‘ä½“1": [0, 9900, 4200, 1200],
            "é‡‡å…‰1": [4200, 8400, 5100, 2700],
            "é‡‡å…‰2": [0, 0, 6000, 1800]
        },
        "rooms_to_generate": ["é‡‡å…‰3", "å§å®¤1", "å§å®¤2", "å®¢å…", "å§å®¤3", "å¨æˆ¿", "å«ç”Ÿé—´", "é¤å…"],
        # çœŸå®æ ‡ç­¾ï¼ˆç”¨äºå¯¹æ¯”ï¼‰
        "ground_truth": {
            "é‡‡å…‰3": [7200, 3600, 2100, 1800],
            "å§å®¤1": [3600, 1800, 2400, 2700],
            "å§å®¤2": [6000, 0, 3300, 3600],
            "å®¢å…": [0, 1800, 3600, 2700],
            "å§å®¤3": [6600, 5400, 2700, 3000],
            "å¨æˆ¿": [1800, 7800, 2400, 2100],
            "å«ç”Ÿé—´": [3300, 6000, 2100, 2400],
            "é¤å…": [1800, 6000, 1500, 1800]
        }
    },
    "åŸå¸‚å°æˆ·å‹_O07": {
        "image": "LLaMA-Factory/data/input_image/city_s_O-07_mix.jpeg",
        "house_type": "åŸå¸‚",
        "floor_type": "ä¸€å±‚",
        "existing_params": {
            "è¾¹ç•Œ": [0, 0, 9600, 10500],
            "ä¸»å…¥å£": [6900, 7200, 1200, 1200],
            "å—é‡‡å…‰": [0, -1200, 9600, 1200],
        },
        "rooms_to_generate": ["å®¢å…", "å§å®¤1", "å¨æˆ¿", "å«ç”Ÿé—´"],
        "ground_truth": None
    },
}


def find_available_model() -> str:
    """æŸ¥æ‰¾å¯ç”¨çš„åŸºåº§æ¨¡å‹è·¯å¾„"""
    candidates = [
        # ç›¸å¯¹è·¯å¾„
        Path("models/Qwen2.5-VL-7B-Instruct"),
        Path("models/Qwen/Qwen2.5-VL-7B-Instruct"),
        # å¸¸è§ç¼“å­˜è·¯å¾„ (Windows)
        Path.home() / ".cache" / "huggingface" / "hub" / "models--Qwen--Qwen2.5-VL-7B-Instruct",
        Path.home() / ".cache" / "modelscope" / "hub" / "models" / "Qwen" / "Qwen2___5-VL-7B-Instruct",
    ]
    
    for p in candidates:
        if p.exists():
            logger.info(f"æ‰¾åˆ°æœ¬åœ°æ¨¡å‹: {p}")
            return str(p)
    
    # è¿”å› HuggingFace IDï¼Œè®© transformers è‡ªåŠ¨ä¸‹è½½
    logger.info("æœ¬åœ°æœªæ‰¾åˆ°æ¨¡å‹ï¼Œå°†ä½¿ç”¨ HuggingFace è‡ªåŠ¨ä¸‹è½½: Qwen/Qwen2.5-VL-7B-Instruct")
    return "Qwen/Qwen2.5-VL-7B-Instruct"


def run_generation(
    test_case_name: str = "åŸå¸‚ä¸€å±‚_A0",
    num_candidates: int = 5,
    score_threshold: float = 80.0,
    max_iterations: int = 3,
    base_model_path: str = None,
    output_dir: str = "output",
):
    """
    è¿è¡Œå®Œæ•´ç”Ÿæˆæµç¨‹
    
    Args:
        test_case_name: æµ‹è¯•ç”¨ä¾‹åç§°
        num_candidates: æ¯è½®å€™é€‰æ•°
        score_threshold: æ»¡æ„åˆ†æ•°é˜ˆå€¼
        max_iterations: æœ€å¤§è¿­ä»£è½®æ•°
        base_model_path: åŸºåº§æ¨¡å‹è·¯å¾„ï¼ˆé»˜è®¤è‡ªåŠ¨æŸ¥æ‰¾ï¼‰
        output_dir: è¾“å‡ºç›®å½•
    """
    # é€‰æ‹©æµ‹è¯•ç”¨ä¾‹
    if test_case_name not in TEST_CASES:
        print(f"å¯ç”¨çš„æµ‹è¯•ç”¨ä¾‹: {list(TEST_CASES.keys())}")
        return
    
    case = TEST_CASES[test_case_name]
    
    # æ£€æŸ¥å›¾ç‰‡æ˜¯å¦å­˜åœ¨
    image_path = Path(case["image"])
    if not image_path.exists():
        image_path = Path(__file__).parent / case["image"]
    if not image_path.exists():
        print(f"âŒ å›¾ç‰‡ä¸å­˜åœ¨: {case['image']}")
        print("è¯·ç¡®è®¤å›¾ç‰‡è·¯å¾„")
        return
    
    print("=" * 70)
    print(f"ğŸ  æˆ·å‹å¸ƒå±€ç”Ÿæˆ - å®Œæ•´ä¼˜åŒ–æµç¨‹")
    print(f"=" * 70)
    print(f"  æµ‹è¯•ç”¨ä¾‹: {test_case_name}")
    print(f"  å›¾ç‰‡è·¯å¾„: {image_path}")
    print(f"  æˆ·å‹ç±»å‹: {case['house_type']} {case['floor_type']}")
    print(f"  å·²æœ‰æˆ¿é—´: {len(case['existing_params'])} ä¸ª")
    print(f"  å¾…ç”Ÿæˆæˆ¿é—´: {case['rooms_to_generate']}")
    print(f"  æ¯è½®å€™é€‰æ•°: {num_candidates}")
    print(f"  æ»¡æ„é˜ˆå€¼: {score_threshold}")
    print(f"  æœ€å¤§è¿­ä»£: {max_iterations}")
    print(f"=" * 70)
    
    # ========== ç¬¬1æ­¥ï¼šåˆå§‹åŒ–æ¨¡å‹ ==========
    print("\nğŸ“¦ [1/4] åŠ è½½æ¨¡å‹...")
    model_path = base_model_path or find_available_model()
    
    predictor = LayoutPredictor(
        base_model_path=model_path,
        lora_adapter_path="lora_model",
        device="cuda"
    )
    predictor.load_model()
    print(f"  âœ… æ¨¡å‹åŠ è½½å®Œæˆ")
    
    # ========== ç¬¬2æ­¥ï¼šæ„å»ºæŸ¥è¯¢ ==========
    print("\nğŸ“ [2/4] æ„å»ºå¸¦è®¾è®¡çº¦æŸçš„æŸ¥è¯¢...")
    query = build_query(
        house_type=case["house_type"],
        floor_type=case["floor_type"],
        existing_params=case["existing_params"],
        rooms_to_generate=case["rooms_to_generate"],
        prompts_config=predictor.prompts_config  # æ³¨å…¥è®¾è®¡çº¦æŸ
    )
    print(f"  æŸ¥è¯¢é•¿åº¦: {len(query)} å­—ç¬¦")
    has_constraints = 'ä¸èƒ½é‡å ' in query or 'è®¾è®¡çº¦æŸ' in query
    print(f"  è®¾è®¡çº¦æŸå·²æ³¨å…¥: {has_constraints}")
    
    # ========== ç¬¬3æ­¥ï¼šä¼˜åŒ–ç”Ÿæˆ ==========
    print("\nğŸ”„ [3/4] å¼€å§‹ä¼˜åŒ–ç”Ÿæˆæµç¨‹...")
    result = predictor.generate_optimized(
        image_path=str(image_path),
        query=query,
        existing_layout=case["existing_params"],
        num_candidates=num_candidates,
        score_threshold=score_threshold,
        max_iterations=max_iterations,
        auto_fix=True,
        improvement_threshold=3.0
    )
    
    # ========== ç¬¬4æ­¥ï¼šè¾“å‡ºç»“æœ ==========
    print(f"\nğŸ“Š [4/4] æœ€ç»ˆç»“æœ:")
    print(f"  å¾—åˆ†: {result.score:.1f}/100")
    print(f"  æ˜¯å¦æ»¡æ„: {'âœ… æ˜¯' if result.is_satisfactory else 'âŒ å¦'}")
    print(f"  æ€»å€™é€‰æ•°: {result.candidates_count}")
    print(f"  è¿­ä»£è½®æ•°: {result.optimization_rounds}")
    
    if result.layout:
        print(f"\n  ç”Ÿæˆçš„å¸ƒå±€:")
        print(f"  {json.dumps(result.layout, ensure_ascii=False, indent=4)}")
    
    if result.issues:
        print(f"\n  âš ï¸ å‰©ä½™é—®é¢˜:")
        for issue in result.issues:
            print(f"    - {issue}")
    
    if result.suggestions:
        print(f"\n  ğŸ’¡ å»ºè®®:")
        for suggestion in result.suggestions:
            print(f"    - {suggestion}")
    
    # è¿­ä»£å†å²
    if result.iteration_history:
        print(f"\n  ğŸ“ˆ è¿­ä»£å†å²:")
        for h in result.iteration_history:
            print(f"    ç¬¬{h['iteration']}è½®: "
                  f"ç±»å‹={h['query_type']}, "
                  f"å€™é€‰={h.get('num_candidates', 0)}, "
                  f"æœ‰æ•ˆ={h.get('num_valid', 0)}, "
                  f"æœ€ä¼˜={h.get('best_score', 0):.1f}, "
                  f"æå‡={h.get('improvement', 0):.1f}")
    
    # ä¸çœŸå®æ ‡ç­¾å¯¹æ¯”
    if case.get("ground_truth") and result.layout:
        print(f"\n  ğŸ“ ä¸çœŸå®æ ‡ç­¾å¯¹æ¯”:")
        gt = case["ground_truth"]
        for room in case["rooms_to_generate"]:
            if room in result.layout and room in gt:
                gen = result.layout[room]
                ref = gt[room]
                diff = sum(abs(a - b) for a, b in zip(gen, ref))
                print(f"    {room}: ç”Ÿæˆ={gen}, æ ‡ç­¾={ref}, åå·®={diff}mm")
            elif room in result.layout:
                print(f"    {room}: ç”Ÿæˆ={result.layout[room]}, æ ‡ç­¾=æ— ")
            else:
                print(f"    {room}: âŒ æœªç”Ÿæˆ")
    
    # ä¿å­˜ç»“æœ
    out_dir = Path(output_dir)
    out_dir.mkdir(exist_ok=True)
    
    result_data = {
        "test_case": test_case_name,
        "score": result.score,
        "is_satisfactory": result.is_satisfactory,
        "candidates_count": result.candidates_count,
        "optimization_rounds": result.optimization_rounds,
        "layout": result.layout,
        "issues": result.issues,
        "suggestions": result.suggestions,
        "iteration_history": result.iteration_history
    }
    
    result_file = out_dir / f"result_{test_case_name}.json"
    with open(result_file, 'w', encoding='utf-8') as f:
        json.dump(result_data, f, ensure_ascii=False, indent=2)
    print(f"\n  ğŸ’¾ ç»“æœå·²ä¿å­˜: {result_file}")
    
    # å¯è§†åŒ–
    try:
        from utils import LayoutVisualizer
        visualizer = LayoutVisualizer()
        
        # åˆå¹¶å®Œæ•´å¸ƒå±€
        full_layout = {**case["existing_params"]}
        if result.layout:
            full_layout.update(result.layout)
        
        fig = visualizer.visualize(
            full_layout,
            title=f"{test_case_name} (å¾—åˆ†: {result.score:.1f})",
            save_path=str(out_dir / f"layout_{test_case_name}.png")
        )
        
        import matplotlib.pyplot as plt
        plt.close(fig)
        print(f"  ğŸ“Š å¯è§†åŒ–å·²ä¿å­˜: {out_dir / f'layout_{test_case_name}.png'}")
    except ImportError:
        print("  è·³è¿‡å¯è§†åŒ–ï¼ˆç¼ºå°‘ matplotlibï¼‰")
    
    print(f"\n{'=' * 70}")
    print(f"âœ… ç”Ÿæˆå®Œæˆ!")
    print(f"{'=' * 70}")
    
    return result


def run_batch(num_cases: int = 3, **kwargs):
    """æ‰¹é‡è¿è¡Œå¤šä¸ªæµ‹è¯•ç”¨ä¾‹"""
    cases = list(TEST_CASES.keys())[:num_cases]
    results = {}
    
    for name in cases:
        print(f"\n\n{'#' * 70}")
        print(f"# æµ‹è¯•ç”¨ä¾‹: {name}")
        print(f"{'#' * 70}")
        result = run_generation(test_case_name=name, **kwargs)
        if result:
            results[name] = result.score
    
    print(f"\n\n{'=' * 70}")
    print(f"ğŸ“‹ æ‰¹é‡è¿è¡Œæ±‡æ€»:")
    for name, score in results.items():
        print(f"  {name}: {score:.1f}")
    print(f"{'=' * 70}")


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="æˆ·å‹å¸ƒå±€å®Œæ•´ç”Ÿæˆ")
    parser.add_argument(
        "--case", type=str, default="åŸå¸‚ä¸€å±‚_A0",
        help=f"æµ‹è¯•ç”¨ä¾‹åç§°ï¼Œå¯é€‰: {list(TEST_CASES.keys())}"
    )
    parser.add_argument("--candidates", type=int, default=5, help="æ¯è½®å€™é€‰æ•° (é»˜è®¤5)")
    parser.add_argument("--threshold", type=float, default=80.0, help="æ»¡æ„åˆ†æ•°é˜ˆå€¼ (é»˜è®¤80)")
    parser.add_argument("--iterations", type=int, default=3, help="æœ€å¤§è¿­ä»£è½®æ•° (é»˜è®¤3)")
    parser.add_argument("--model", type=str, default=None, help="åŸºåº§æ¨¡å‹è·¯å¾„ (é»˜è®¤è‡ªåŠ¨æŸ¥æ‰¾)")
    parser.add_argument("--output", type=str, default="output", help="è¾“å‡ºç›®å½•")
    parser.add_argument("--batch", action="store_true", help="æ‰¹é‡è¿è¡Œæ‰€æœ‰æµ‹è¯•ç”¨ä¾‹")
    
    args = parser.parse_args()
    
    if args.batch:
        run_batch(
            num_candidates=args.candidates,
            score_threshold=args.threshold,
            max_iterations=args.iterations,
            base_model_path=args.model,
            output_dir=args.output
        )
    else:
        run_generation(
            test_case_name=args.case,
            num_candidates=args.candidates,
            score_threshold=args.threshold,
            max_iterations=args.iterations,
            base_model_path=args.model,
            output_dir=args.output
        )
