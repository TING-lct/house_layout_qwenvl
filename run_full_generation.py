"""
æˆ·å‹å¸ƒå±€å®Œæ•´ç”Ÿæˆè„šæœ¬ â€”â€” ç›´æ¥è¿è¡Œå³å¯

è¿è¡Œæ–¹å¼ï¼š
    python run_full_generation.py

éœ€è¦ç¯å¢ƒï¼š
    - GPU (è‡³å°‘16GBæ˜¾å­˜ï¼Œæ¨è24GB)
    - å·²å®‰è£…: transformers, peft, torch, qwen_vl_utils
    - åŸºåº§æ¨¡å‹: Qwen2.5-VL-7B-Instructï¼ˆé¦–æ¬¡è¿è¡Œè‡ªåŠ¨ä¸‹è½½æˆ–æ‰‹åŠ¨æ”¾åˆ° models/ ä¸‹ï¼‰
    - LoRAé€‚é…å™¨: lora_model/ï¼ˆå·²åŒ…å«åœ¨é¡¹ç›®ä¸­ï¼‰

å®Œæ•´ä¼˜åŒ–æµç¨‹ï¼š
    è¾“å…¥å›¾ç‰‡ + å·²æœ‰å‚æ•°
      â†’ æç¤ºè¯å¢å¼ºï¼ˆæ³¨å…¥è®¾è®¡çº¦æŸï¼‰
      â†’ å¤šå€™é€‰ç”Ÿæˆï¼ˆ5ä¸ªä¸åŒæ¸©åº¦é‡‡æ ·ï¼‰
      â†’ äº”ç»´åº¦è¯„ä¼°æ‰“åˆ†
      â†’ é€‰æ‹©æœ€ä¼˜ + è§„åˆ™ä¿®å¤
      â†’ å¦‚æœä¸è¾¾æ ‡: é—®é¢˜æ³¨å…¥Prompt â†’ é‡æ–°ç”Ÿæˆ
      â†’ å¾ªç¯ç›´åˆ°æ»¡æ„ï¼ˆæˆ–è¾¾åˆ°æœ€å¤§è½®æ¬¡ï¼‰
      â†’ è¾“å‡ºæœ€ç»ˆç»“æœ + å¯è§†åŒ–
"""

from layout_predictor import LayoutPredictor, build_query
import json
import sys
import logging
import argparse
from typing import Optional
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent))


logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s [%(name)s] %(message)s',
    datefmt='%H:%M:%S'
)
logger = logging.getLogger("main")


# ==================== æµ‹è¯•ç”¨ä¾‹ ====================
# æ¥è‡ªè®­ç»ƒæ•°æ®é›† dataset_house_floor_test.json ç¬¬ä¸€æ¡æ•°æ®

TEST_CASES = {
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ åŸå¸‚å¤§æˆ·å‹ (city_l) â”€ æ¥è‡ª test æ•°æ®é›† â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    "åŸå¸‚å¤§_A0": {
        "image": "LLaMA-Factory/data/input_image/city_l_A0_mix.jpeg",
        "house_type": "åŸå¸‚",
        "floor_type": "ä¸€å±‚",
        "existing_params": {
            "è¾¹ç•Œ": [0, 0, 9300, 11100],
            "ä¸»å…¥å£": [300, 9900, 1200, 1200],
            "å—é‡‡å…‰": [0, -1200, 9300, 1200],
            "åŒ—é‡‡å…‰": [0, 11100, 9300, 1200],
            "ä¸œé‡‡å…‰": [9300, 0, 1200, 11100],
            "é»‘ä½“1": [0, 9900, 4200, 1200],
            "é‡‡å…‰1": [4200, 8400, 5100, 2700],
            "é‡‡å…‰2": [0, 0, 6000, 1800],
        },
        "rooms_to_generate": ["é‡‡å…‰3", "å§å®¤1", "å§å®¤2", "å®¢å…", "å§å®¤3", "å¨æˆ¿", "å«ç”Ÿé—´", "é¤å…"],
        "ground_truth": {
            "é‡‡å…‰3": [7200, 3600, 2100, 1800],
            "å§å®¤1": [3600, 1800, 2400, 2700],
            "å§å®¤2": [6000, 0, 3300, 3600],
            "å®¢å…": [0, 1800, 3600, 2700],
            "å§å®¤3": [6600, 5400, 2700, 3000],
            "å¨æˆ¿": [1800, 7800, 2400, 2100],
            "å«ç”Ÿé—´": [3300, 6000, 2100, 2400],
            "é¤å…": [1800, 6000, 1500, 1800],
        },
    },
    "åŸå¸‚å¤§_A1": {
        "image": "LLaMA-Factory/data/input_image/city_l_A1-1-æ— -2_mix.jpeg",
        "house_type": "åŸå¸‚",
        "floor_type": "ä¸€å±‚",
        "existing_params": {
            "è¾¹ç•Œ": [0, 0, 9300, 8400],
            "ä¸»å…¥å£": [8100, 3300, 1200, 900],
            "å—é‡‡å…‰": [0, -600, 9300, 600],
            "åŒ—é‡‡å…‰": [0, 8400, 9300, 600],
            "ä¸œé‡‡å…‰": [9300, 0, 600, 8400],
            "é»‘ä½“1": [8100, 0, 1200, 3300],
            "é‡‡å…‰1": [0, 5700, 4200, 2700],
        },
        "rooms_to_generate": ["é‡‡å…‰3", "å§å®¤1", "å§å®¤2", "å®¢å…", "å¨æˆ¿", "ä¸»å«", "é¤å…"],
        "ground_truth": {
            "é‡‡å…‰3": [4200, 5700, 2400, 2700],
            "å§å®¤1": [0, 0, 3600, 2700],
            "å§å®¤2": [0, 2700, 4200, 3000],
            "å®¢å…": [4200, 2700, 3900, 3000],
            "å¨æˆ¿": [6600, 5700, 2700, 2700],
            "ä¸»å«": [3600, 0, 4500, 2700],
            "é¤å…": [4200, 0, 3900, 2700],
        },
    },
    "åŸå¸‚å¤§_G81": {
        "image": "LLaMA-Factory/data/input_image/city_l_G81-1-æ— -1_mix.jpeg",
        "house_type": "åŸå¸‚",
        "floor_type": "ä¸€å±‚",
        "existing_params": {
            "è¾¹ç•Œ": [0, 0, 7500, 15000],
            "ä¸»å…¥å£": [1800, 14400, 1200, 600],
            "å—é‡‡å…‰": [0, -600, 7500, 600],
            "åŒ—é‡‡å…‰": [0, 15000, 7500, 600],
            "é»‘ä½“1": [1800, 10200, 2100, 1800],
            "é‡‡å…‰1": [0, 12000, 3900, 3000],
            "é‡‡å…‰2": [0, 6300, 3600, 3000],
            "å§å®¤1": [3600, 6300, 3900, 3000],
            "å§å®¤2": [3600, 0, 3900, 3300],
        },
        "rooms_to_generate": ["å®¢å…", "å§å®¤3", "å¨æˆ¿", "å«ç”Ÿé—´", "ä¸»å«", "é¤å…"],
        "ground_truth": {
            "å®¢å…": [3900, 10200, 3600, 4800],
            "å§å®¤3": [0, 0, 3600, 3300],
            "å¨æˆ¿": [0, 3300, 3600, 3000],
            "å«ç”Ÿé—´": [3600, 3300, 3900, 3000],
            "ä¸»å«": [0, 9300, 1800, 2700],
            "é¤å…": [0, 12000, 3900, 3000],
        },
    },

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ åŸå¸‚å°æˆ·å‹ (city_s) â”€ æ¥è‡ª train æ•°æ®é›† â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    "åŸå¸‚å°_A01": {
        "image": "LLaMA-Factory/data/input_image/city_s_A-01_mix.jpeg",
        "house_type": "åŸå¸‚",
        "floor_type": "ä¸€å±‚",
        "existing_params": {
            "è¾¹ç•Œ": [0, 0, 4200, 5700],
            "ä¸»å…¥å£": [900, -600, 900, 600],
            "åŒ—é‡‡å…‰": [0, 5700, 4200, 600],
            "é»‘ä½“1": [0, 4200, 600, 1500],
            "å§å®¤1": [600, 4200, 3600, 1500],
        },
        "rooms_to_generate": ["å®¢å…", "å¨æˆ¿", "å«ç”Ÿé—´"],
        "ground_truth": {
            "å®¢å…": [0, 2400, 4200, 1800],
            "å¨æˆ¿": [0, 0, 900, 2400],
            "å«ç”Ÿé—´": [2400, 0, 1800, 2400],
        },
    },
    "åŸå¸‚å°_K01": {
        "image": "LLaMA-Factory/data/input_image/city_s_K-01_mix.jpeg",
        "house_type": "åŸå¸‚",
        "floor_type": "ä¸€å±‚",
        "existing_params": {
            "è¾¹ç•Œ": [0, 0, 6900, 9900],
            "ä¸»å…¥å£": [0, 8700, 1200, 900],
            "å—é‡‡å…‰": [0, -900, 6900, 900],
            "åŒ—é‡‡å…‰": [0, 9900, 6900, 900],
            "é»‘ä½“1": [0, 8700, 1200, 900],
            "é‡‡å…‰1": [3600, 8700, 3300, 1200],
            "å§å®¤1": [3600, 6000, 3300, 2700],
            "å§å®¤2": [3600, 0, 3300, 3900],
            "å®¢å…": [0, 0, 3600, 3900],
        },
        "rooms_to_generate": ["å¨æˆ¿", "å«ç”Ÿé—´", "é¤å…"],
        "ground_truth": {
            "å¨æˆ¿": [1200, 6600, 2400, 3300],
            "å«ç”Ÿé—´": [4500, 3900, 2400, 2100],
            "é¤å…": [1200, 4800, 2400, 1800],
        },
    },

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ä¹¡æ‘æˆ·å‹ (rural) â”€ æ¥è‡ª train æ•°æ®é›† â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    "ä¹¡æ‘_BL100": {
        "image": "LLaMA-Factory/data/input_image/rural_f_B-L-100_mix.jpeg",
        "house_type": "ä¹¡æ‘",
        "floor_type": "ä¸€å±‚",
        "existing_params": {
            "è¾¹ç•Œ": [0, 0, 12000, 15300],
            "é™¢é—¨": [4200, -1200, 1200, 1200],
            "é™¢å­": [0, 0, 6900, 5100],
            "ä¸»å…¥å£": [5100, 3900, 1200, 1200],
            "å—é‡‡å…‰": [0, -1200, 12000, 1200],
            "åŒ—é‡‡å…‰": [0, 15300, 12000, 1200],
            "ä¸œé‡‡å…‰": [12000, 0, 1200, 15300],
            "è¥¿é‡‡å…‰": [-1200, 0, 1200, 15300],
            "å§å®¤1": [8100, 5100, 3900, 5100],
            "å§å®¤2": [8100, 10200, 3900, 5100],
            "å®¢å…": [6900, 0, 5100, 5100],
            "å¨æˆ¿": [0, 10200, 3900, 3000],
            "æ¥¼æ¢¯": [0, 13200, 3900, 2100],
            "å«ç”Ÿé—´": [0, 8100, 3900, 2100],
        },
        "rooms_to_generate": ["å‚¨è—", "ç„å…³", "é¤å…"],
        "ground_truth": {
            "å‚¨è—": [0, 5100, 3900, 3000],
            "ç„å…³": [3900, 5100, 4200, 5100],
            "é¤å…": [3900, 10200, 4200, 5100],
        },
    },
    "ä¹¡æ‘_EI53": {
        "image": "LLaMA-Factory/data/input_image/rural_f_E-I-53_mix.jpeg",
        "house_type": "ä¹¡æ‘",
        "floor_type": "ä¸€å±‚",
        "existing_params": {
            "è¾¹ç•Œ": [0, 0, 13200, 9900],
            "é™¢å­": [9900, 6300, 3300, 3600],
            "ä¸»å…¥å£": [5400, 600, 900, 900],
            "é—¨å»Š": [0, 0, 9900, 1500],
            "å—é‡‡å…‰": [0, -1200, 13200, 1200],
            "åŒ—é‡‡å…‰": [0, 9900, 13200, 1200],
            "è¥¿é‡‡å…‰": [-1200, 0, 1200, 9900],
            "é»‘ä½“1": [13200, 0, 1200, 9900],
            "å§å®¤1": [9900, 0, 3300, 4500],
            "å§å®¤2": [0, 1500, 3300, 3900],
            "å®¢å…": [3300, 1500, 6600, 3900],
        },
        "rooms_to_generate": ["å¨æˆ¿", "å«ç”Ÿé—´", "ä¸»å«", "å‚¨è—", "é¤å…", "æ¬¡å…¥å£"],
        "ground_truth": {
            "å¨æˆ¿": [0, 7500, 3300, 2400],
            "å«ç”Ÿé—´": [0, 5400, 3300, 2100],
            "ä¸»å«": [11100, 4500, 2100, 1800],
            "å‚¨è—": [6600, 6300, 3300, 3600],
            "é¤å…": [3300, 6300, 3300, 3600],
            "æ¬¡å…¥å£": [3300, 9900, 900, 900],
        },
    },
}


def find_available_model() -> str:
    """æŸ¥æ‰¾å¯ç”¨çš„åŸºåº§æ¨¡å‹è·¯å¾„"""
    def _is_model_dir_complete(model_dir: Path) -> bool:
        """æ£€æŸ¥æœ¬åœ°æ¨¡å‹ç›®å½•æ˜¯å¦å®Œæ•´ï¼ˆé‡ç‚¹æ£€æŸ¥ safetensors åˆ†ç‰‡ï¼‰"""
        if not model_dir.exists() or not model_dir.is_dir():
            return False

        # åŸºç¡€é…ç½®æ–‡ä»¶è‡³å°‘åº”å­˜åœ¨ä¸€ä¸ª
        has_config = (model_dir / "config.json").exists()
        if not has_config:
            return False

        index_file = model_dir / "model.safetensors.index.json"
        if index_file.exists():
            try:
                data = json.loads(index_file.read_text(encoding="utf-8"))
                weight_map = data.get("weight_map", {})
                shard_files = sorted(set(weight_map.values()))
                if not shard_files:
                    logger.warning(f"æ¨¡å‹ç´¢å¼•ä¸ºç©ºï¼Œè·³è¿‡: {model_dir}")
                    return False

                missing = [name for name in shard_files if not (
                    model_dir / name).exists()]
                if missing:
                    logger.warning(
                        "æœ¬åœ°æ¨¡å‹åˆ†ç‰‡ä¸å®Œæ•´ï¼Œç¼ºå¤± %d ä¸ªæ–‡ä»¶ï¼ˆç¤ºä¾‹: %sï¼‰ï¼Œè·³è¿‡: %s",
                        len(missing),
                        missing[0],
                        model_dir,
                    )
                    return False
                return True
            except Exception as e:
                logger.warning(f"è¯»å–æ¨¡å‹ç´¢å¼•å¤±è´¥ï¼Œè·³è¿‡: {model_dir}, é”™è¯¯: {e}")
                return False

        # å…¼å®¹æ— ç´¢å¼•åœºæ™¯ï¼šè‡³å°‘æœ‰ä¸€ä¸ªæƒé‡æ–‡ä»¶
        has_single_bin = (model_dir / "pytorch_model.bin").exists()
        has_single_safe = (model_dir / "model.safetensors").exists()
        has_shards = bool(list(model_dir.glob("model-*-of-*.safetensors")))
        return has_single_bin or has_single_safe or has_shards

    candidates = [
        # ç›¸å¯¹è·¯å¾„
        Path("models/Qwen2.5-VL-7B-Instruct"),
        Path("models/Qwen/Qwen2.5-VL-7B-Instruct"),
        # AutoDL ç›®å½•ï¼ˆäº‘æœåŠ¡å™¨ï¼‰
        Path("/root/autodl-tmp/models/Qwen2.5-VL-7B-Instruct"),
        Path("/autodl-tmp/models/Qwen2.5-VL-7B-Instruct"),
        # å¸¸è§ç¼“å­˜è·¯å¾„ (Windows)
        Path.home() / ".cache" / "huggingface" / "hub" /
        "models--Qwen--Qwen2.5-VL-7B-Instruct",
        Path.home() / ".cache" / "modelscope" / "hub" /
        "models" / "Qwen" / "Qwen2___5-VL-7B-Instruct",
    ]

    for p in candidates:
        if _is_model_dir_complete(p):
            logger.info(f"æ‰¾åˆ°æœ¬åœ°æ¨¡å‹: {p}")
            return str(p)
        elif p.exists():
            logger.warning(f"æ£€æµ‹åˆ°æœ¬åœ°æ¨¡å‹ç›®å½•ä½†ä¸å®Œæ•´ï¼Œå·²è·³è¿‡: {p}")

    # è¿”å› HuggingFace IDï¼Œè®© transformers è‡ªåŠ¨ä¸‹è½½
    logger.info("æœ¬åœ°æœªæ‰¾åˆ°æ¨¡å‹ï¼Œå°†ä½¿ç”¨ HuggingFace è‡ªåŠ¨ä¸‹è½½: Qwen/Qwen2.5-VL-7B-Instruct")
    return "Qwen/Qwen2.5-VL-7B-Instruct"


def _calc_iou(rect1: list, rect2: list) -> float:
    """è®¡ç®—ä¸¤ä¸ªçŸ©å½¢çš„IoU (Intersection over Union)

    Args:
        rect1, rect2: [x, y, width, height]

    Returns:
        float: IoUå€¼ (0~1)
    """
    x1, y1, w1, h1 = rect1
    x2, y2, w2, h2 = rect2

    # è®¡ç®—äº¤é›†
    inter_x1 = max(x1, x2)
    inter_y1 = max(y1, y2)
    inter_x2 = min(x1 + w1, x2 + w2)
    inter_y2 = min(y1 + h1, y2 + h2)

    if inter_x2 <= inter_x1 or inter_y2 <= inter_y1:
        return 0.0

    inter_area = (inter_x2 - inter_x1) * (inter_y2 - inter_y1)
    union_area = w1 * h1 + w2 * h2 - inter_area
    return inter_area / union_area if union_area > 0 else 0.0


def _calc_center_offset(rect1: list, rect2: list) -> float:
    """è®¡ç®—ä¸¤ä¸ªçŸ©å½¢ä¸­å¿ƒç‚¹çš„æ¬§æ°è·ç¦»"""
    cx1 = rect1[0] + rect1[2] / 2
    cy1 = rect1[1] + rect1[3] / 2
    cx2 = rect2[0] + rect2[2] / 2
    cy2 = rect2[1] + rect2[3] / 2
    return ((cx1 - cx2) ** 2 + (cy1 - cy2) ** 2) ** 0.5


def run_generation(
    test_case_name: str = "åŸå¸‚å¤§_A0",
    num_candidates: int = 5,
    score_threshold: float = 80.0,
    max_iterations: int = 3,
    base_model_path: Optional[str] = None,
    output_dir: str = "output",
):
    """
    è¿è¡Œå®Œæ•´ç”Ÿæˆæµç¨‹

    Args:
        test_case_name: æµ‹è¯•ç”¨ä¾‹åç§°
        num_candidates: æ¯è½®å€™é€‰æ•°
        score_threshold: æ»¡æ„åˆ†æ•°é˜ˆå€¼
        max_iterations: æœ€å¤§è¿­ä»£è½®æ•°
        base_model_path: åŸºåº§æ¨¡å‹è·¯å¾„ï¼ˆé»˜è®¤è‡ªåŠ¨æŸ¥æ‰¾ï¼‰
        output_dir: è¾“å‡ºç›®å½•
    """
    # é€‰æ‹©æµ‹è¯•ç”¨ä¾‹
    if test_case_name not in TEST_CASES:
        print(f"å¯ç”¨çš„æµ‹è¯•ç”¨ä¾‹: {list(TEST_CASES.keys())}")
        return

    case = TEST_CASES[test_case_name]

    # æ£€æŸ¥å›¾ç‰‡æ˜¯å¦å­˜åœ¨
    image_path = Path(case["image"])
    if not image_path.exists():
        image_path = Path(__file__).parent / case["image"]
    if not image_path.exists():
        print(f"âŒ å›¾ç‰‡ä¸å­˜åœ¨: {case['image']}")
        print("è¯·ç¡®è®¤å›¾ç‰‡è·¯å¾„")
        return

    print("=" * 70)
    print(f"ğŸ  æˆ·å‹å¸ƒå±€ç”Ÿæˆ - å®Œæ•´ä¼˜åŒ–æµç¨‹")
    print(f"=" * 70)
    print(f"  æµ‹è¯•ç”¨ä¾‹: {test_case_name}")
    print(f"  å›¾ç‰‡è·¯å¾„: {image_path}")
    print(f"  æˆ·å‹ç±»å‹: {case['house_type']} {case['floor_type']}")
    print(f"  å·²æœ‰æˆ¿é—´: {len(case['existing_params'])} ä¸ª")
    print(f"  å¾…ç”Ÿæˆæˆ¿é—´: {case['rooms_to_generate']}")
    print(f"  æ¯è½®å€™é€‰æ•°: {num_candidates}")
    print(f"  æ»¡æ„é˜ˆå€¼: {score_threshold}")
    print(f"  æœ€å¤§è¿­ä»£: {max_iterations}")
    print(f"=" * 70)

    # ========== ç¬¬1æ­¥ï¼šåˆå§‹åŒ–æ¨¡å‹ ==========
    print("\nğŸ“¦ [1/4] åŠ è½½æ¨¡å‹...")
    model_path = base_model_path or find_available_model()

    predictor = LayoutPredictor(
        base_model_path=model_path,
        lora_adapter_path="lora_model",
        device="cuda"
    )
    predictor.load_model()
    print(f"  âœ… æ¨¡å‹åŠ è½½å®Œæˆ")

    # ========== ç¬¬2æ­¥ï¼šæ„å»ºæŸ¥è¯¢ ==========
    print("\nğŸ“ [2/4] æ„å»ºæŸ¥è¯¢ï¼ˆä¸è®­ç»ƒæ•°æ®æ ¼å¼ä¸€è‡´ï¼‰...")
    query = build_query(
        house_type=case["house_type"],
        floor_type=case["floor_type"],
        existing_params=case["existing_params"],
        rooms_to_generate=case["rooms_to_generate"]
    )
    print(f"  æŸ¥è¯¢é•¿åº¦: {len(query)} å­—ç¬¦")

    # ========== ç¬¬3æ­¥ï¼šä¼˜åŒ–ç”Ÿæˆ ==========
    print("\nğŸ”„ [3/4] å¼€å§‹ä¼˜åŒ–ç”Ÿæˆæµç¨‹...")
    result = predictor.generate_optimized(
        image_path=str(image_path),
        query=query,
        existing_layout=case["existing_params"],
        num_candidates=num_candidates,
        score_threshold=score_threshold,
        max_iterations=max_iterations,
        auto_fix=True,
        improvement_threshold=1.0
    )

    # ========== ç¬¬4æ­¥ï¼šè¾“å‡ºç»“æœ ==========
    print(f"\nğŸ“Š [4/4] æœ€ç»ˆç»“æœ:")
    print(f"  å¾—åˆ†: {result.score:.1f}/100")
    print(f"  æ˜¯å¦æ»¡æ„: {'âœ… æ˜¯' if result.is_satisfactory else 'âŒ å¦'}")
    print(f"  æ€»å€™é€‰æ•°: {result.candidates_count}")
    print(f"  è¿­ä»£è½®æ•°: {result.optimization_rounds}")

    if result.layout:
        print(f"\n  ç”Ÿæˆçš„å¸ƒå±€:")
        print(f"  {json.dumps(result.layout, ensure_ascii=False, indent=4)}")

    if result.issues:
        print(f"\n  âš ï¸ å‰©ä½™é—®é¢˜:")
        for issue in result.issues:
            print(f"    - {issue}")

    if result.suggestions:
        print(f"\n  ğŸ’¡ å»ºè®®:")
        for suggestion in result.suggestions:
            print(f"    - {suggestion}")

    # è¿­ä»£å†å²
    if result.iteration_history:
        print(f"\n  ğŸ“ˆ è¿­ä»£å†å²:")
        for h in result.iteration_history:
            print(f"    ç¬¬{h['iteration']}è½®: "
                  f"ç±»å‹={h['query_type']}, "
                  f"å€™é€‰={h.get('num_candidates', 0)}, "
                  f"æœ‰æ•ˆ={h.get('num_valid', 0)}, "
                  f"æœ€ä¼˜={h.get('best_score', 0):.1f}, "
                  f"æå‡={h.get('improvement', 0):.1f}")

    # åˆå§‹åŒ–ç»“æœæ•°æ®
    result_data = {
        "test_case": test_case_name,
        "score": result.score,
        "is_satisfactory": result.is_satisfactory,
        "candidates_count": result.candidates_count,
        "optimization_rounds": result.optimization_rounds,
        "layout": result.layout,
        "issues": result.issues,
        "suggestions": result.suggestions,
        "iteration_history": result.iteration_history,
    }

    # ä¸çœŸå®æ ‡ç­¾å¯¹æ¯”
    if case.get("ground_truth") and result.layout:
        print(f"\n  ğŸ“ ä¸çœŸå®æ ‡ç­¾å¯¹æ¯”:")
        gt = case["ground_truth"]
        ious = []
        for room in case["rooms_to_generate"]:
            if room in result.layout and room in gt:
                gen = result.layout[room]
                ref = gt[room]
                diff = sum(abs(a - b) for a, b in zip(gen, ref))
                iou = _calc_iou(gen, ref)
                offset = _calc_center_offset(gen, ref)
                ious.append(iou)
                status = "âœ…" if iou > 0.5 else "âš ï¸" if iou > 0.2 else "âŒ"
                print(f"    {status} {room}: ç”Ÿæˆ={gen}, æ ‡ç­¾={ref}, "
                      f"åå·®={diff}mm, IoU={iou:.3f}, ä¸­å¿ƒåç§»={offset:.0f}mm")
            elif room in result.layout:
                print(f"    â“ {room}: ç”Ÿæˆ={result.layout[room]}, æ ‡ç­¾=æ— ")
                ious.append(0.0)
            else:
                print(f"    âŒ {room}: æœªç”Ÿæˆ")
                ious.append(0.0)
        if ious:
            avg_iou = sum(ious) / len(ious)
            good_count = sum(1 for x in ious if x > 0.5)
            print(f"    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")
            print(f"    ğŸ“Š å¹³å‡IoU: {avg_iou:.3f}")
            print(f"    ğŸ“Š IoU>0.5çš„æˆ¿é—´: {good_count}/{len(ious)}")
            result_data["avg_iou"] = avg_iou
            result_data["room_ious"] = {room: _calc_iou(result.layout.get(room, [0, 0, 0, 0]), gt.get(room, [0, 0, 0, 0]))
                                        for room in case["rooms_to_generate"] if room in gt}

    # ä¿å­˜ç»“æœ
    out_dir = Path(output_dir)
    out_dir.mkdir(exist_ok=True)

    result_file = out_dir / f"result_{test_case_name}.json"
    with open(result_file, 'w', encoding='utf-8') as f:
        json.dump(result_data, f, ensure_ascii=False, indent=2)
    print(f"\n  ğŸ’¾ ç»“æœå·²ä¿å­˜: {result_file}")

    # å¯è§†åŒ–
    try:
        from utils import LayoutVisualizer
        visualizer = LayoutVisualizer()

        # åˆå¹¶å®Œæ•´å¸ƒå±€
        full_layout = {**case["existing_params"]}
        if result.layout:
            full_layout.update(result.layout)

        # é«˜äº®ç”Ÿæˆçš„æˆ¿é—´
        highlight = list(result.layout.keys()) if result.layout else []

        fig = visualizer.visualize(
            full_layout,
            title=f"{test_case_name} (å¾—åˆ†: {result.score:.1f})",
            show_labels=True,
            show_dimensions=True,
            highlight_rooms=highlight,
            save_path=str(out_dir / f"layout_{test_case_name}.png")
        )

        import matplotlib.pyplot as plt
        plt.close(fig)
        print(f"  ğŸ“Š å¯è§†åŒ–å·²ä¿å­˜: {out_dir / f'layout_{test_case_name}.png'}")

        # å¦‚æœæœ‰ground truthï¼Œç”Ÿæˆå¯¹æ¯”å›¾
        if case.get("ground_truth") and result.layout:
            gt_layout = {**case["existing_params"], **case["ground_truth"]}
            gen_layout = {**case["existing_params"], **result.layout}
            fig_cmp = visualizer.compare_layouts(
                [gen_layout, gt_layout],
                titles=[f"ç”Ÿæˆç»“æœ (å¾—åˆ†: {result.score:.1f})",
                        "çœŸå®æ ‡ç­¾ (Ground Truth)"],
                save_path=str(out_dir / f"compare_{test_case_name}.png")
            )
            plt.close(fig_cmp)
            print(f"  ğŸ“Š å¯¹æ¯”å›¾å·²ä¿å­˜: {out_dir / f'compare_{test_case_name}.png'}")
    except ImportError:
        print("  è·³è¿‡å¯è§†åŒ–ï¼ˆç¼ºå°‘ matplotlibï¼‰")

    print(f"\n{'=' * 70}")
    print(f"âœ… ç”Ÿæˆå®Œæˆ!")
    print(f"{'=' * 70}")

    return result


def run_batch(num_cases: int = 0, **kwargs):
    """æ‰¹é‡è¿è¡Œå¤šä¸ªæµ‹è¯•ç”¨ä¾‹ (num_cases=0 è¡¨ç¤ºå…¨éƒ¨)"""
    cases = list(TEST_CASES.keys())[
        :num_cases] if num_cases > 0 else list(TEST_CASES.keys())
    results = {}

    for name in cases:
        print(f"\n\n{'#' * 70}")
        print(f"# æµ‹è¯•ç”¨ä¾‹: {name}")
        print(f"{'#' * 70}")
        result = run_generation(test_case_name=name, **kwargs)
        if result:
            results[name] = result.score

    print(f"\n\n{'=' * 70}")
    print(f"ğŸ“‹ æ‰¹é‡è¿è¡Œæ±‡æ€»:")
    for name, score in results.items():
        print(f"  {name}: {score:.1f}")
    print(f"{'=' * 70}")


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="æˆ·å‹å¸ƒå±€å®Œæ•´ç”Ÿæˆ")
    parser.add_argument(
        "--case", type=str, default="åŸå¸‚å¤§_A0",
        help=f"æµ‹è¯•ç”¨ä¾‹åç§°ï¼Œå¯é€‰: {list(TEST_CASES.keys())}"
    )
    parser.add_argument("--candidates", type=int,
                        default=5, help="æ¯è½®å€™é€‰æ•° (é»˜è®¤5)")
    parser.add_argument("--threshold", type=float,
                        default=95.0, help="æ»¡æ„åˆ†æ•°é˜ˆå€¼ (é»˜è®¤95)")
    parser.add_argument("--iterations", type=int,
                        default=5, help="æœ€å¤§è¿­ä»£è½®æ•° (é»˜è®¤5)")
    parser.add_argument("--model", type=str, default=None,
                        help="åŸºåº§æ¨¡å‹è·¯å¾„ (é»˜è®¤è‡ªåŠ¨æŸ¥æ‰¾)")
    parser.add_argument("--output", type=str, default="output", help="è¾“å‡ºç›®å½•")
    parser.add_argument("--batch", action="store_true", help="æ‰¹é‡è¿è¡Œæ‰€æœ‰æµ‹è¯•ç”¨ä¾‹")

    args = parser.parse_args()

    if args.batch:
        run_batch(
            num_candidates=args.candidates,
            score_threshold=args.threshold,
            max_iterations=args.iterations,
            base_model_path=args.model,
            output_dir=args.output
        )
    else:
        run_generation(
            test_case_name=args.case,
            num_candidates=args.candidates,
            score_threshold=args.threshold,
            max_iterations=args.iterations,
            base_model_path=args.model,
            output_dir=args.output
        )
