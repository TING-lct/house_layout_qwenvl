"""
æ¨¡å‹ä¸‹è½½è„šæœ¬ â€”â€” è‡ªåŠ¨ä¸‹è½½æ‰€æœ‰éœ€è¦çš„åŸºåº§æ¨¡å‹

è¿è¡Œæ–¹å¼ï¼š
    python download_models.py              # ä¸‹è½½å…¨éƒ¨æ¨¡å‹
    python download_models.py --only 7b    # åªä¸‹è½½7Bç”Ÿæˆæ¨¡å‹
    python download_models.py --only 14b   # åªä¸‹è½½14Bè¯„ä¼°æ¨¡å‹
    python download_models.py --only embed # åªä¸‹è½½RAGå‘é‡æ¨¡å‹
    python download_models.py --source modelscope  # ä»ModelScopeä¸‹è½½(å›½å†…æ¨è)

æ¨¡å‹æ¸…å•ï¼š
    â‘  Qwen2.5-VL-7B-Instruct  (~15GB)  - æˆ·å‹å›¾ç”Ÿæˆæ¨¡å‹ï¼ˆå¿…éœ€ï¼‰
    â‘¡ Qwen2.5-14B-Instruct    (~28GB)  - LLMè¯„ä¼°æ¨¡å‹ï¼ˆå¯é€‰ï¼Œæå‡è¯„ä¼°è´¨é‡ï¼‰
    â‘¢ paraphrase-multilingual-MiniLM-L12-v2 (~0.5GB) - RAGå‘é‡æ¨¡å‹ï¼ˆå¯é€‰ï¼‰

ä¸‹è½½ä½ç½®ï¼š
    models/Qwen2.5-VL-7B-Instruct/
    models/Qwen2.5-14B-Instruct/
    models/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/
"""

import os
import sys
import argparse
import subprocess
from pathlib import Path

# é¡¹ç›®æ ¹ç›®å½•
PROJECT_ROOT = Path(__file__).parent
DEFAULT_MODELS_DIR = PROJECT_ROOT.parent / "models"


# ==================== æ¨¡å‹å®šä¹‰ ====================

def build_models(models_dir: Path) -> dict:
    return {
        "7b": {
            "name": "Qwen2.5-VL-7B-Instruct",
            "desc": "æˆ·å‹å›¾ç”Ÿæˆæ¨¡å‹ï¼ˆå¿…éœ€ï¼Œ~15GBï¼‰",
            "huggingface_id": "Qwen/Qwen2.5-VL-7B-Instruct",
            "modelscope_id": "Qwen/Qwen2.5-VL-7B-Instruct",
            "local_dir": models_dir / "Qwen2.5-VL-7B-Instruct",
            "required": True,
        },
        "14b": {
            "name": "Qwen2.5-14B-Instruct",
            "desc": "LLMè¯„ä¼°æ¨¡å‹ï¼ˆå¯é€‰ï¼Œ~28GBï¼‰",
            "huggingface_id": "Qwen/Qwen2.5-14B-Instruct",
            "modelscope_id": "Qwen/Qwen2.5-14B-Instruct",
            "local_dir": models_dir / "Qwen2.5-14B-Instruct",
            "required": False,
        },
        "embed": {
            "name": "paraphrase-multilingual-MiniLM-L12-v2",
            "desc": "RAGå‘é‡åµŒå…¥æ¨¡å‹ï¼ˆå¯é€‰ï¼Œ~0.5GBï¼‰",
            "huggingface_id": "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2",
            "modelscope_id": "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2",
            "local_dir": models_dir / "sentence-transformers" / "paraphrase-multilingual-MiniLM-L12-v2",
            "required": False,
        },
    }


# ==================== ä¸‹è½½å‡½æ•° ====================

def check_model_exists(model_info: dict) -> bool:
    """æ£€æŸ¥æ¨¡å‹æ˜¯å¦å·²ä¸‹è½½"""
    local_dir = model_info["local_dir"]
    if not local_dir.exists():
        return False
    # æ£€æŸ¥æ˜¯å¦æœ‰å®é™…æ¨¡å‹æ–‡ä»¶
    has_safetensors = any(local_dir.glob("*.safetensors"))
    has_bin = any(local_dir.glob("*.bin"))
    has_config = (local_dir / "config.json").exists()
    return has_config and (has_safetensors or has_bin)


def get_disk_free_gb(path: Path) -> float:
    """è·å–ç£ç›˜å‰©ä½™ç©ºé—´(GB)"""
    import shutil
    total, used, free = shutil.disk_usage(path.anchor)
    return free / (1024 ** 3)


def download_from_huggingface(model_info: dict, models_dir: Path) -> bool:
    """ä» HuggingFace ä¸‹è½½æ¨¡å‹"""
    model_id = model_info["huggingface_id"]
    local_dir = model_info["local_dir"]
    
    print(f"  ğŸ“¥ ä» HuggingFace ä¸‹è½½: {model_id}")
    print(f"  ğŸ“‚ ä¿å­˜åˆ°: {local_dir}")
    
    try:
        from huggingface_hub import snapshot_download
        
        local_dir.parent.mkdir(parents=True, exist_ok=True)
        
        snapshot_download(
            repo_id=model_id,
            local_dir=str(local_dir),
            resume_download=True,  # æ”¯æŒæ–­ç‚¹ç»­ä¼ 
            max_workers=4,
        )
        return True
        
    except ImportError:
        print("  âš ï¸  huggingface_hub æœªå®‰è£…ï¼Œå°è¯• pip å®‰è£…...")
        subprocess.check_call([sys.executable, "-m", "pip", "install", "huggingface_hub"])
        from huggingface_hub import snapshot_download
        
        local_dir.parent.mkdir(parents=True, exist_ok=True)
        snapshot_download(
            repo_id=model_id,
            local_dir=str(local_dir),
            resume_download=True,
            max_workers=4,
        )
        return True


def download_from_modelscope(model_info: dict, models_dir: Path) -> bool:
    """ä» ModelScope ä¸‹è½½æ¨¡å‹ï¼ˆå›½å†…æ¨èï¼‰"""
    model_id = model_info["modelscope_id"]
    local_dir = model_info["local_dir"]
    
    print(f"  ğŸ“¥ ä» ModelScope ä¸‹è½½: {model_id}")
    print(f"  ğŸ“‚ ä¿å­˜åˆ°: {local_dir}")
    
    try:
        from modelscope import snapshot_download as ms_download
        
        local_dir.parent.mkdir(parents=True, exist_ok=True)
        
        ms_download(
            model_id,
            cache_dir=str(models_dir),
            revision="master",
        )
        
        # ModelScope ä¸‹è½½çš„ç›®å½•ç»“æ„å¯èƒ½ä¸åŒï¼Œåšä¸€ä¸‹å…¼å®¹
        ms_cache_dir = models_dir / model_id.replace("/", os.sep)
        if ms_cache_dir.exists() and not local_dir.exists():
            ms_cache_dir.rename(local_dir)
        
        return True
        
    except ImportError:
        print("  âš ï¸  modelscope æœªå®‰è£…ï¼Œå°è¯• pip å®‰è£…...")
        subprocess.check_call([sys.executable, "-m", "pip", "install", "modelscope"])
        from modelscope import snapshot_download as ms_download
        
        local_dir.parent.mkdir(parents=True, exist_ok=True)
        ms_download(
            model_id,
            cache_dir=str(models_dir),
            revision="master",
        )
        return True


def download_model(
    key: str,
    models: dict,
    models_dir: Path,
    source: str = "huggingface",
    force: bool = False,
) -> bool:
    """
    ä¸‹è½½æŒ‡å®šæ¨¡å‹
    
    Args:
        key: æ¨¡å‹æ ‡è¯† (7b / 14b / embed)
        source: ä¸‹è½½æº (huggingface / modelscope)
    """
    model_info = models[key]
    
    print(f"\n{'='*60}")
    print(f"ğŸ“¦ {model_info['name']}")
    print(f"   {model_info['desc']}")
    print(f"{'='*60}")
    
    # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
    if check_model_exists(model_info) and not force:
        print(f"  âœ… å·²å­˜åœ¨ï¼Œè·³è¿‡ä¸‹è½½: {model_info['local_dir']}")
        return True

    if force and model_info["local_dir"].exists():
        print(f"  â™»ï¸ å¼ºåˆ¶é‡ä¸‹ï¼Œå…ˆåˆ é™¤æ—§ç›®å½•: {model_info['local_dir']}")
        import shutil
        shutil.rmtree(model_info["local_dir"], ignore_errors=True)
    
    # æ£€æŸ¥ç£ç›˜ç©ºé—´
    free_gb = get_disk_free_gb(models_dir if models_dir.exists() else PROJECT_ROOT)
    size_needed = {"7b": 16, "14b": 30, "embed": 1}[key]
    
    if free_gb < size_needed:
        print(f"  âŒ ç£ç›˜ç©ºé—´ä¸è¶³! éœ€è¦ ~{size_needed}GB, å½“å‰å‰©ä½™ {free_gb:.1f}GB")
        return False
    
    print(f"  ğŸ’¾ ç£ç›˜å‰©ä½™: {free_gb:.1f}GB, é¢„è®¡éœ€è¦: ~{size_needed}GB")
    
    # ä¸‹è½½
    try:
        if source == "modelscope":
            return download_from_modelscope(model_info, models_dir)
        else:
            return download_from_huggingface(model_info, models_dir)
    except Exception as e:
        print(f"  âŒ ä¸‹è½½å¤±è´¥: {e}")
        
        # å¦‚æœ HuggingFace å¤±è´¥ï¼Œæç¤ºä½¿ç”¨ ModelScope
        if source == "huggingface":
            print(f"\n  ğŸ’¡ å¦‚æœ HuggingFace è®¿é—®å—é™ï¼Œè¯·å°è¯• ModelScope:")
            print(f"     python download_models.py --source modelscope")
        
        return False


# ==================== ä¸»æµç¨‹ ====================

def main():
    parser = argparse.ArgumentParser(
        description="ä¸‹è½½æˆ·å‹å›¾ç”Ÿæˆé¡¹ç›®æ‰€éœ€çš„åŸºåº§æ¨¡å‹",
        formatter_class=argparse.RawTextHelpFormatter
    )
    parser.add_argument(
        "--only", type=str, default=None,
        choices=["7b", "14b", "embed"],
        help="åªä¸‹è½½æŒ‡å®šæ¨¡å‹:\n  7b    - Qwen2.5-VL-7B-Instruct (ç”Ÿæˆï¼Œå¿…éœ€)\n  14b   - Qwen2.5-14B-Instruct (è¯„ä¼°ï¼Œå¯é€‰)\n  embed - å‘é‡åµŒå…¥æ¨¡å‹ (RAGï¼Œå¯é€‰)"
    )
    parser.add_argument(
        "--source", type=str, default="huggingface",
        choices=["huggingface", "modelscope"],
        help="ä¸‹è½½æº:\n  huggingface - HuggingFace Hub (é»˜è®¤)\n  modelscope  - ModelScope (å›½å†…æ¨è)"
    )
    parser.add_argument(
        "--all", action="store_true",
        help="ä¸‹è½½å…¨éƒ¨æ¨¡å‹ï¼ˆåŒ…æ‹¬å¯é€‰æ¨¡å‹ï¼‰"
    )
    parser.add_argument(
        "--models-dir", type=str, default=str(DEFAULT_MODELS_DIR),
        help="æ¨¡å‹ä¿å­˜ç›®å½•ï¼ˆé»˜è®¤: é¡¹ç›®åŒçº§ modelsï¼‰"
    )
    parser.add_argument(
        "--force", action="store_true",
        help="å¼ºåˆ¶é‡ä¸‹ï¼ˆåˆ é™¤å·²å­˜åœ¨ç›®å½•åé‡ä¸‹ï¼‰"
    )
    
    args = parser.parse_args()
    
    models_dir = Path(args.models_dir).resolve()
    models = build_models(models_dir)

    print("=" * 60)
    print("ğŸ  æˆ·å‹å›¾ç”Ÿæˆ - æ¨¡å‹ä¸‹è½½å·¥å…·")
    print("=" * 60)
    print(f"  ä¸‹è½½æº: {args.source}")
    print(f"  ä¿å­˜ç›®å½•: {models_dir}")
    
    # åˆ›å»º models ç›®å½•
    models_dir.mkdir(parents=True, exist_ok=True)
    
    # ç¡®å®šè¦ä¸‹è½½çš„æ¨¡å‹
    if args.only:
        targets = [args.only]
    elif args.all:
        targets = ["7b", "14b", "embed"]
    else:
        # é»˜è®¤åªä¸‹è½½å¿…éœ€æ¨¡å‹
        targets = ["7b"]
        print("\n  é»˜è®¤åªä¸‹è½½å¿…éœ€çš„ 7B ç”Ÿæˆæ¨¡å‹")
        print("  å¦‚éœ€å…¨éƒ¨æ¨¡å‹ï¼Œè¯·ä½¿ç”¨: python download_models.py --all")
    
    # å…ˆæ˜¾ç¤ºè®¡åˆ’
    print(f"\nğŸ“‹ ä¸‹è½½è®¡åˆ’:")
    for key in targets:
        m = models[key]
        exists = "âœ… å·²å­˜åœ¨" if check_model_exists(m) else "â³ å¾…ä¸‹è½½"
        required = "å¿…éœ€" if m["required"] else "å¯é€‰"
        print(f"  [{required}] {m['name']} - {exists}")
    
    # æ‰§è¡Œä¸‹è½½
    results = {}
    for key in targets:
        success = download_model(
            key,
            models=models,
            models_dir=models_dir,
            source=args.source,
            force=args.force,
        )
        results[key] = success
    
    # æ±‡æ€»
    print(f"\n\n{'='*60}")
    print("ğŸ“‹ ä¸‹è½½ç»“æœ:")
    print(f"{'='*60}")
    
    all_ok = True
    for key, success in results.items():
        m = models[key]
        status = "âœ… æˆåŠŸ" if success else "âŒ å¤±è´¥"
        print(f"  {status} - {m['name']}")
        if not success and m["required"]:
            all_ok = False
    
    # æ£€æŸ¥ LoRA é€‚é…å™¨
    lora_path = PROJECT_ROOT / "lora_model"
    lora_14b_path = PROJECT_ROOT.parent / "qwen14b" / "Qwen2.5-14B-Instruct" / "Qwen2.5-14B-Instruct" / "lora" / "train_2025-12-01-21-17-23"
    
    print(f"\nğŸ“ LoRA é€‚é…å™¨:")
    print(f"  7Bç”ŸæˆLoRA:  {'âœ…' if lora_path.exists() else 'âŒ'} {lora_path}")
    print(f"  14Bè¯„ä¼°LoRA: {'âœ…' if lora_14b_path.exists() else 'âŒ'} {lora_14b_path}")
    
    if all_ok:
        print(f"\nğŸ‰ æ¨¡å‹å‡†å¤‡å°±ç»ªï¼å¯ä»¥è¿è¡Œ:")
        print(f"   python run_full_generation.py")
    else:
        print(f"\nâš ï¸  éƒ¨åˆ†å¿…éœ€æ¨¡å‹ä¸‹è½½å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç½‘ç»œåé‡è¯•")
    
    print(f"{'='*60}")


if __name__ == "__main__":
    main()
